# Docker Compose Environment Configuration
# Copy this file to .env and customize the values for your deployment

# Backend Configuration
BACKEND_PORT=8000
BACKEND_LOG_LEVEL=info

# Frontend Configuration
FRONTEND_PORT=3000

# API Configuration
# Note: You need to create the following files in the backend directory:
# - backend/nvdev_api.txt (NVIDIA API key, optional)
# - backend/tavily_api.txt (Tavily API key, required)
# - backend/openai_api.txt (OpenAI API key, optional)
# - backend/openrouter_api.txt (OpenRouter API key, optional)

# LLM Configuration
# Available models:
# - NVIDIA: llama-3.1-nemotron-253b, llama-3.1-nemotron-8b, llama-3.1-8b
# - OpenRouter: openrouter/anthropic/claude-3.5-sonnet, openrouter/openai/gpt-4,
#               openrouter/meta-llama/llama-3.1-70b-instruct, openrouter/google/gemini-2.0-flash-exp,
#               openrouter/mistralai/mistral-large, openrouter/openai/gpt-oss-120b-free
DEFAULT_MODEL=openrouter/openai/gpt-oss-120b-free
LLM_BASE_URL=https://openrouter.ai/api/v1

# Research Configuration
MAX_TOPICS=1
MAX_SEARCH_PHRASES=1
MAX_SEARCH_RESULTS=10
