# Использование OpenRouter с Universal Deep Research

OpenRouter предоставляет унифицированный доступ к множеству LLM провайдеров через единый API. Это позволяет легко переключаться между различными моделями без изменения кода.

## Преимущества OpenRouter

- **Единый API** для доступа к десяткам моделей от разных провайдеров
- **Конкурентные цены** с автоматическим выбором наиболее выгодного провайдера
- **Бесплатные модели** для тестирования и разработки
- **Автоматическое переключение** между провайдерами при недоступности
- **Прозрачная аналитика** использования и затрат
- **Простая интеграция** с существующим кодом

## Поддерживаемые модели

Universal Deep Research поддерживает следующие модели через OpenRouter:

### Anthropic Claude

```env
DEFAULT_MODEL=openrouter/anthropic/claude-3.5-sonnet
```

Claude 3.5 Sonnet — одна из самых мощных моделей для анализа и генерации текста.

**Характеристики:**
- Отличное качество рассуждений
- Большой контекстный размер (200K токенов)
- Хорошо следует инструкциям
- Подходит для сложных исследовательских задач

### OpenAI GPT-4

```env
DEFAULT_MODEL=openrouter/openai/gpt-4
```

GPT-4 — проверенная временем модель с отличными результатами.

**Характеристики:**
- Высокое качество генерации
- Хорошая работа с различными языками
- Стабильные результаты
- Широкие возможности

### Meta Llama 3.1 70B

```env
DEFAULT_MODEL=openrouter/meta-llama/llama-3.1-70b-instruct
```

Llama 3.1 70B — мощная открытая модель от Meta.

**Характеристики:**
- Отличное соотношение цена/качество
- Быстрая генерация
- Хорошо работает с инструкциями
- Поддержка длинного контекста (128K токенов)

### Google Gemini 2.0 Flash

```env
DEFAULT_MODEL=openrouter/google/gemini-2.0-flash-exp
```

Gemini 2.0 Flash — экспериментальная модель от Google с высокой скоростью.

**Характеристики:**
- Очень быстрая генерация
- Мультимодальные возможности
- Хорошее качество для большинства задач
- Часто доступна бесплатно

### GPT-OSS 120B (Free)

```env
DEFAULT_MODEL=openrouter/openai/gpt-oss-120b-free
```

GPT-OSS 120B — бесплатная модель, которая теперь является дефолтной.

**Характеристики:**
- **Бесплатное использование**
- Хорошее качество для общих задач
- Отличный выбор для быстрого старта

### Mistral Large

```env
DEFAULT_MODEL=openrouter/mistralai/mistral-large
```

Mistral Large — европейская альтернатива с отличным качеством.

**Характеристики:**
- Высокое качество генерации
- Хорошая работа с кодом
- Поддержка функций (function calling)
- Конкурентные цены

## Настройка

### 1. Получение API ключа

1. Перейдите на [OpenRouter](https://openrouter.ai/)
2. Зарегистрируйтесь или войдите в аккаунт
3. Перейдите в раздел [Keys](https://openrouter.ai/keys)
4. Создайте новый API ключ
5. Скопируйте ключ (он показывается только один раз!)

### 2. Конфигурация проекта

#### Для Docker Compose

API ключи теперь задаются через переменные окружения в файле `.env` в корне проекта.

1. **Создайте файл `.env`** из примера:
```bash
cp .env.example .env
```

2. **Заполните `.env`** вашим ключом OpenRouter и URL сервисов:
```env
# .env file content (пример)
OPENROUTER_API_KEY=ваш-openrouter-api-ключ
FRONTEND_URL=http://localhost:3000
BACKEND_URL=http://localhost:8000
```

3. **Запустите сервисы**:
```bash
docker compose up -d
```

#### Для ручной установки

API ключи теперь задаются через переменные окружения в файле `.env` в директории `apps/backend`.

1. **Создайте файл `.env`** из примера:
```bash
cd apps/backend
cp env.example .env
```

2. **Заполните `.env`** вашим ключом OpenRouter и URL сервисов:
```env
# .env file content (пример)
OPENROUTER_API_KEY=ваш-openrouter-api-ключ
FRONTEND_URL=http://localhost:3000
BACKEND_URL=http://localhost:8000
```

3. **Запустите backend**:
```bash
./launch_server.sh
```

## Выбор модели

Вы можете выбрать модель несколькими способами:

### 1. Через переменную окружения

```env
# Дефолтная модель (бесплатная)
DEFAULT_MODEL=openrouter/openai/gpt-oss-120b-free
```

### 2. Через API запрос

При использовании API v2 вы можете указать модель в запросе:

```json
{
  "prompt": "Ваш исследовательский вопрос",
  "model": "openrouter/openai/gpt-4"
}
```

### 3. Программно в коде

В `clients.py` вы можете создать клиент с конкретной моделью:

```python
from clients import create_lm_client, MODEL_CONFIGS

# Использовать Claude
client = create_lm_client(MODEL_CONFIGS["openrouter/anthropic/claude-3.5-sonnet"])
```

## Сравнение моделей

| Модель | Скорость | Качество | Цена | Контекст | Рекомендация |
|--------|----------|----------|------|----------|--------------|
| Claude 3.5 Sonnet | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | $$$ | 200K | Сложные задачи |
| GPT-4 | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | $$$$ | 128K | Универсальное |
| Llama 3.1 70B | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | $$ | 128K | Цена/качество |
| Gemini 2.0 Flash | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | $ | 1M | Быстрые задачи |
| Mistral Large | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | $$ | 128K | Код и анализ |

## Мониторинг использования

OpenRouter предоставляет подробную аналитику использования:

1. Перейдите на [OpenRouter Dashboard](https://openrouter.ai/activity)
2. Просмотрите историю запросов
3. Отслеживайте затраты
4. Анализируйте производительность моделей

## Оптимизация затрат

### 1. Используйте бесплатные модели для тестирования

Некоторые модели доступны бесплатно:
- Gemini 2.0 Flash (экспериментальная)
- Llama 3.1 8B (через некоторых провайдеров)

### 2. Настройте лимиты

В OpenRouter можно установить лимиты расходов:

```bash
# В настройках аккаунта установите месячный лимит
```

### 3. Кэшируйте результаты

Backend автоматически кэширует результаты поиска, что снижает количество запросов к LLM.

### 4. Выбирайте подходящую модель

Для простых задач используйте более дешевые модели:
- Gemini Flash для быстрых ответов
- Llama 3.1 70B для баланса цены и качества
- Claude или GPT-4 только для сложных задач

## Устранение неполадок

### Ошибка: API key not found

Проверьте, что файл `apps/backend/openrouter_api.txt` существует и содержит валидный ключ:

```bash
cat apps/backend/openrouter_api.txt
```

### Ошибка: Model not found

Убедитесь, что название модели указано правильно с префиксом `openrouter/`:

```env
# Правильно
DEFAULT_MODEL=openrouter/anthropic/claude-3.5-sonnet

# Неправильно
DEFAULT_MODEL=anthropic/claude-3.5-sonnet
```

### Ошибка: Rate limit exceeded

OpenRouter имеет лимиты запросов. Подождите немного или обновите план:

1. Проверьте лимиты на [странице аккаунта](https://openrouter.ai/settings)
2. Рассмотрите возможность повышения лимитов
3. Добавьте задержки между запросами

### Медленная генерация

Некоторые модели медленнее других. Попробуйте:

1. Использовать более быструю модель (Gemini Flash, Llama)
2. Уменьшить `max_tokens` в конфигурации
3. Проверить статус провайдера на [странице статуса](https://openrouter.ai/status)

## Дополнительные возможности

### Fallback модели

OpenRouter автоматически переключается на альтернативную модель, если основная недоступна.

### Приоритет провайдеров

Вы можете указать предпочитаемых провайдеров через заголовки HTTP (требует модификации кода).

### Streaming

Все модели OpenRouter поддерживают streaming для real-time обновлений.

## Полезные ссылки

- [OpenRouter Documentation](https://openrouter.ai/docs)
- [Список доступных моделей](https://openrouter.ai/models)
- [Цены на модели](https://openrouter.ai/models?order=newest)
- [API Reference](https://openrouter.ai/docs/api-reference)
- [Discord сообщество](https://discord.gg/openrouter)

## Примеры использования

### Исследование с Claude

```bash
# Настроить модель
export DEFAULT_MODEL=openrouter/anthropic/claude-3.5-sonnet

# Запустить исследование
curl -X POST http://localhost:8000/api/research \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Какие последние достижения в области ИИ?",
    "start_from": "research"
  }'
```

### Быстрый анализ с Gemini

```bash
# Настроить модель
export DEFAULT_MODEL=openrouter/google/gemini-2.0-flash-exp

# Запустить исследование
curl -X POST http://localhost:8000/api/research \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Краткий обзор рынка криптовалют",
    "start_from": "research"
  }'
```

## Заключение

OpenRouter предоставляет простой и эффективный способ использования множества LLM моделей в Universal Deep Research. Выбирайте модель в зависимости от ваших требований к качеству, скорости и бюджету.

Для получения дополнительной помощи обратитесь к [основной документации](README.ru.md) или создайте issue в репозитории.
