# Предложения по рефакторингу и эффективности

Этот документ описывает возможности повысить эффективность и улучшить архитектуру конвейера research, сохраняя текущий общий подход.

## Наблюдаемые узкие места

- **Последовательное, блокирующее выполнение.** `do_research` проходит по темам → поисковым фразам → результатам поиска синхронно, включая каждый вызов Tavily и завершение LLM, поэтому суммарная задержка растёт мультипликативно с числом тем и фраз.【F:backend/scan_research.py†L157-L259】
- **LLM-вызовы на каждый результат.** Для каждого результата поиска вызывается `find_relevant_segments`, создавая много мелких обращений вместо пакетирования или стриминга, что увеличивает накладные расходы по токенам и задержку.【F:backend/scan_research.py†L228-L259】【F:backend/scan_research.py†L475-L495】
- **Построение отчёта копирует большие строки.** Совокупная строка с сегментами формируется на каждый отчёт и затем снова конкатенируется при добавлении источников, что может быть тяжёлым при большом числе сегментов.【F:backend/scan_research.py†L498-L520】【F:backend/scan_research.py†L334-L369】
- **Жёсткая связка с глобальным состоянием.** Глобальные `config` и фабрики клиентов читаются напрямую, что усложняет юнит-тестирование частей или замену провайдеров без изменения глобального состояния.【F:backend/scan_research.py†L30-L38】【F:backend/scan_research.py†L310-L327】

## Идеи по рефакторингу (обратная совместимость)

1. **Добавить конкурентность с ограниченным числом воркеров.**
   - Использовать `asyncio.TaskGroup`/`gather` для распараллеливания Tavily-поисков и вызовов `find_relevant_segments` по каждой теме с семафором для ограничения параллельности и защиты от rate limit.
   - Сохранять порядок выдаваемых событий для темы, буферизуя завершившиеся задачи перед отправкой клиенту.

2. **Пакетировать извлечение релевантности в LLM.**
   - Разрешить `find_relevant_segments` принимать список поисковых результатов и возвращать сгруппированные абзацы по URL за одно завершение (например, пронумерованные блоки), сокращая накладные расходы на промпты/ответы при сохранении существующего подхода к оценке.

3. **Добавить лёгкое кеширование.**
   - Кешировать выходы `perform_search` по `(topic, search_phrase)` и мемоизировать `find_relevant_segments` по `(url, prompt, topic)`, чтобы избежать перерасчётов при ретраях или повторяющихся входных данных.

4. **Упростить сборку отчёта.**
   - Строить список источников через `"\n".join` по заранее подготовленному шаблону вместо пошаговой конкатенации строк и избежать дублирования большой `topic_relevant_segments_str` между шагами, передавая структурированные данные в `produce_report`.

5. **Улучшить композицию и тестируемость.**
   - Передавать экземпляры клиентов и объекты конфигурации явно в помощники вместо чтения глобальных, а чистые преобразования данных (например, индексацию URL) выносить в небольшие функции для таргетированных юнит-тестов без внешних сервисов.

6. **Повысить устойчивость и наблюдаемость.**
   - Добавить таймауты и обёртки с ретраями/бэкоффом вокруг вызовов Tavily и LLM; отображать длительность отдельных вызовов в метаданных `make_event`, чтобы выявлять медленные этапы при деплоях.

Эти изменения сохраняют текущий функциональный поток (темы → поиски → релевантность → отчёт), снижая задержки, улучшая использование ресурсов и делая конвейер более тестируемым.
