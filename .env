# Docker Compose Environment Configuration
# Copy this file to .env and customize the values for your deployment

# Backend Configuration
BACKEND_PORT=8000
BACKEND_LOG_LEVEL=info

# Frontend Configuration
FRONTEND_URL=http://localhost:3000,http://service-udr-rxhvud-731f4f-185-245-34-200.traefik.me
BACKEND_URL=http://localhost:8000

# API Configuration
# Note: API keys are now set directly as environment variables.
# The default model requires OPENROUTER_API_KEY and TAVILY_API_KEY.
NVDEV_API_KEY=
OPENAI_API_KEY=
OPENROUTER_API_KEY=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
TAVILY_API_KEY=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

# LLM Configuration
# Available models:
# - NVIDIA: llama-3.1-nemotron-253b, llama-3.1-nemotron-8b, llama-3.1-8b
# - OpenRouter: openrouter/anthropic/claude-3.5-sonnet, openrouter/openai/gpt-4,
#               openrouter/meta-llama/llama-3.1-70b-instruct, openrouter/google/gemini-2.0-flash-exp,
#               openrouter/mistralai/mistral-large, openrouter/openai/gpt-oss-120b-free
DEFAULT_MODEL=openrouter/openai/gpt-oss-120b-free
LLM_BASE_URL=https://openrouter.ai/api/v1

# Research Configuration
MAX_TOPICS=1
MAX_SEARCH_PHRASES=1
MAX_SEARCH_RESULTS=10