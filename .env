# Docker Compose Environment Configuration
# Copy this file to .env and customize the values for your deployment

# Backend Configuration
BACKEND_PORT=8000
BACKEND_LOG_LEVEL=info

# Frontend Configuration
FRONTEND_URL=http://localhost:3000
BACKEND_URL=http://localhost:8000

# API Configuration
# Note: API keys are now set directly as environment variables.
# The default model requires OPENROUTER_API_KEY and TAVILY_API_KEY.
NVDEV_API_KEY=
OPENAI_API_KEY=
OPENROUTER_API_KEY=your-openrouter-api-key-here
TAVILY_API_KEY=your-tavily-api-key-here

# LLM Configuration
# Available models:
# - NVIDIA: llama-3.1-nemotron-253b, llama-3.1-nemotron-8b, llama-3.1-8b
# - OpenRouter: openrouter/anthropic/claude-3.5-sonnet, openrouter/openai/gpt-4,
#               openrouter/meta-llama/llama-3.1-70b-instruct, openrouter/google/gemini-2.0-flash-exp,
#               openrouter/mistralai/mistral-large, openrouter/openai/gpt-oss-120b-free
DEFAULT_MODEL=openrouter/openai/gpt-oss-120b-free
LLM_BASE_URL=https://openrouter.ai/api/v1

# Research Configuration
MAX_TOPICS=1
MAX_SEARCH_PHRASES=1
MAX_SEARCH_RESULTS=10

# Additional minimal variables for deployment
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=info